## Схема стенда

<<<<<<< HEAD
![project_scheme](https://raw.githubusercontent.com/Asterroth/z-recovery/7ac7bed/img.png)
=======
![[scheme_1.png]]
>>>>>>> 36155f058c8a6a106322b3a1e9425ff964c86407
### Параметры сети
Сеть 192.168.100.0/24

### Базовые параметры вирт. машины
CPU: 1 core
RAM: 1 GB
Storage: 20 GB
OS: Ubuntu 22.04 server
### Базовые параметры вирт. машины для разворачивания ELK стэка
CPU: 2 core
RAM: 6 GB
Storage: 30 GB
OS: Ubuntu 22.04 server
## Краткое описание стенда
* balancer -- балансировщик на базе проксирующего nginx
* app1 -- сервер apache №1
* app2 -- сервер apache №2
* db-src -- сервер БД MySQL в роли source
* db-repl -- сервер БД MySQL в роли replica
* nfs -- файловое хранилище, в том числе для бэкапов БД
* prometheus -- сервер мониторинга
* elk -- сервер сбора логов

### Конфигурирование доступа по ssh
После запуска ВМ и базовой установки на хосте администратора необходимо сгенерировать ключевую пару:
```bash
ssh-keygen -t ed25519 -C "user@email.com"
```
в процессе интерактивного выполнения утилиты `ssh-keygen` задаем имя нашей пары ключей, например `otus`.
Далее выполняем копирование публичного ключа на каждую ВМ:
```bash
ssh-copy-id -i ./.ssh/otus am@192.168.100.210
```

## Пакеты, скачанные на базовую систему
Пакеты из стандартных репозиториев Ubuntu (пакеты не устанавливают, а только скачиваются: `apt install --download-only`)
* `iptables-persistent`
* `nfs-kernel-server`
* `nfs-common`
* `nginx`
* `apache2`
* `mysql-server-8.0`
* `prometheus-node-exporter`
* `prometheus-nginx-exporter`
* `default-jdk`
Пакеты в виде `.deb` файлов, скачанные заранее и размещенные на NFS
* `elasticsearch_8.9.1_amd64-224190-ed0378.deb`
* `kibana_8.9.1_amd64-224190-939c28.deb`
* `logstash_8.9.1_amd64-224190-d5e2e9.deb`
* `filebeat_8.9.1_amd64-224190-507082.deb`
* `metricbeat_8.9.1_amd64-224190-486369.deb`
* `heartbeat_8.9.1_amd64-224190-b53fb6.deb`
* `grafana_10.4.1_amd64.deb`

## Исходное состояние стенда
Выполнена базовая установка, включая:
* установка ОС;
* создан пользователь `am` с правами `sudo`;
* сконфигурирована сеть и файрвол в соответствии с предназначением хоста;
* настроен часовой пояс UTC+3 (Московское время);
* смонтирована сетевая папка NFS;

## Общая схема восстановления
Проект восстановления хранится в репозитории на github:
`https://github.com/Asterroth/z-recovery`
Для каждого хоста (роли) создана своя директория, в которой хранятся скрипты, а также поддиректория `config` для хранения конфигурационных файлов и других вспомогательных данных.
Два основных скрипта - это:
`network-HOST.sh` и `install-HOST.sh`, где HOST - наименование соответствующего хоста.
Директория `common` в корне репозитория содержит два скрипта:
* `mount-nfs.sh` - подключение сетевого хранилища NFS;
* `timedate.sh` - скрипт установки часового пояса и синхронизации даты/времени.
Директория `base` содержит скрипты базовой установки.

В общем случае восстановление хоста сводится к последовательному выполнению двух скриптов:
1) `network-HOST.sh` - настройки сети и файрвола;
2) `install-HOST.sh.

>[!caution] После выполнения настроек сети соединение ssh будет разорвано, потребуется переподключение по новому IP адресу!

Отдельно выполняется восстановление базы данных из резервной копии и настройки дэшбордов мониторинга (prometheus+grafana) и логирования (ELK+kibana).
## Восстановление ДБ из бэкапа
Резервные копии базы данных приложения хранятся на сервере NFS в директории:
`/mnt/backup-data/db-backup/`
в виде архивных файлов вида `YYYYMMDD_hhmmss_MSK.sql.gz'.

Для восстановления БД на сервере `db-src` необходимо выполнить скрипт:
`/mnt/backup-data/db-restore.sh`, передав ему в качестве параметра имя файла резервной копии, например:
`db-restore.sh 20240608_100110_MSK.sql.gz`

